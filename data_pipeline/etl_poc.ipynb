{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC ETL_1 - Prototype découpé en fonction\n",
    "\n",
    "Vous trouverez les codes sources des fonction dans à ces chemins : \n",
    "- [extract.py](extract.py)\n",
    "- [transform.py](transform.py) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \".env\" not in os.listdir():\n",
    "    os.chdir(\"data4good/13_brigade_coupes_rases/data_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import *\n",
    "from extract import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AWS_SECRET_ACCESS_KEY est bien chargé.\n",
      "✅ AWS_ACCESS_KEY_ID est bien chargé.\n"
     ]
    }
   ],
   "source": [
    "# Vérification du .env\n",
    "load_dotenv(f\".env\")\n",
    "env_vars = [\"AWS_SECRET_ACCESS_KEY\", \"AWS_ACCESS_KEY_ID\"]\n",
    "\n",
    "for var in env_vars:\n",
    "    try:\n",
    "        value = os.environ[var]  \n",
    "        print(f\"✅ {var} est bien chargé.\")\n",
    "    except KeyError:\n",
    "        print(f\"⚠️ Attention : {var} n'est pas défini dans l'environnement !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "bucket_name = \"brc-poc-etl\"\n",
    "api_query = \"mosaics_tropisco_warnings_france_date.tif\"\n",
    "download_path = \"temp_tif/mosaics_tropisco_warnings_france_date.tif\"\n",
    "s3_key = \"raw_data/raster/sufosat_data/mosaics_tropisco_warnings_france_date.tif\"\n",
    "s3_key_metadata = \"raw_data/raster/sufosat_data/mosaics_tropisco_warnings_france_date_metadata.json\"\n",
    "url = \"https://zenodo.org/records/13685177/files/mosaics_tropisco_warnings_france_date.tif?download=1\"\n",
    "\n",
    "s3 = boto3.client(\n",
    "    service_name = \"s3\",\n",
    "    region_name = \"eu-west-3\",\n",
    "    aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE EXTRACT DE L'ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inspection de la metadata effectuée, mise à jour requise : False\n"
     ]
    }
   ],
   "source": [
    "data, do_update = data_update(api_query, bucket_name, s3_key=s3_key, s3_key_metadata=s3_key_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Les données sont déjà à jour, pas besoin de télécharger à nouveau\n"
     ]
    }
   ],
   "source": [
    "if do_update or check_tif_in_s3(bucket_name, s3_key):\n",
    "    print(\"✅ Les données sont déjà à jour, pas besoin de télécharger à nouveau\")\n",
    "else:\n",
    "    extract_tif_data_and_upload(url, s3_key, s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE TRANSFORM DE L'ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier téléchargé depuis S3 temp_tif/mosaics_tropisco_warnings_france_date.tif\n"
     ]
    }
   ],
   "source": [
    "if check_tif_in_s3(bucket_name, s3_key):\n",
    "    load_from_S3(bucket_name, s3_key, download_path)\n",
    "else:\n",
    "    print(\"❌ Le fichier n'est pas sur S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15458it [00:53, 289.56it/s]                                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier tif regroupé\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regroup_sufosat_days(\n",
    "    # Download from \"mosaics_tropisco_warnings_france_date.tif\" from https://zenodo.org/records/13685177\n",
    "    \"temp_tif/mosaics_tropisco_warnings_france_date.tif\",\n",
    "    \"temp_tif/mosaics_tropisco_warnings_france_date_2024.tif\",\n",
    "    pd.Timestamp(year=2024, month=1, day=1),\n",
    "    pd.Timestamp(year=2024, month=12, day=31),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Raster ouvert avec Gdal\n",
      "✅ Fichier shapefile créé\n",
      "✅ Couche SRS créée\n",
      "✅ Polygonisation du raster réussie\n"
     ]
    }
   ],
   "source": [
    "extract_raster_as_geodataframe(\n",
    "    raster_path = \"temp_tif/mosaics_tropisco_warnings_france_date_2024.tif\",\n",
    "    vector_path = \"temp_shape/mosaics_tropisco_warnings_france_date_2024.shp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Calcul de la surface en hectares\n",
      "✅ Calcul des coordonnées\n",
      "✅ Conversion des géométries en WKT\n",
      "✅ Conversion bytes GEOJSON\n"
     ]
    }
   ],
   "source": [
    "sufosat_2024: gpd.GeoDataFrame = gpd.read_file(f\"temp_shape\")\n",
    "sufosat_2024: gpd.GeoDataFrame = transform_raster(sufosat_2024)\n",
    "geojson_bytes = convert_geometries_to_wkt(sufosat_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE LOAD DE L'ETL --> PAS COMPLET \n",
    "> Les données sont chargées sur S3 pas encore dans la base. Un autre pipe pour le vrai load dans la database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier GeoJSON upload sur S3\n"
     ]
    }
   ],
   "source": [
    "upload_geodataframe_to_s3(\n",
    "    geojson_bytes, \n",
    "    bucket_name, \n",
    "    s3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les données uploaded sur S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici les objets présents dans le bucket :\n",
      "- raw_data/raster/sufosat_data/mosaics_tropisco_warnings_france_date.tif\n",
      "- raw_data/raster/sufosat_data/mosaics_tropisco_warnings_france_date_metadata.json\n",
      "- to_api/clear_cut_processed_2025-02-19.geojson\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "result = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "if \"Contents\" in result:\n",
    "    print(\"Voici les objets présents dans le bucket :\")\n",
    "    for obj in result[\"Contents\"]:\n",
    "        print(f\"- {obj['Key']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
